{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202e00af-e507-4302-a7eb-ae2920de0f18",
   "metadata": {},
   "source": [
    "### How to import pandas and check the version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e0ce49-2343-4989-a832-d218c2086ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\qather\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\qather\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\qather\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\qather\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\qather\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\qather\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b444e151-58d5-4f23-bfb6-46ba5285632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n",
      "{\n",
      "  \"system\": {\n",
      "    \"commit\": \"0691c5cf90477d3503834d983f69350f250a6ff7\",\n",
      "    \"python\": \"3.12.1\",\n",
      "    \"python-bits\": 64,\n",
      "    \"OS\": \"Windows\",\n",
      "    \"OS-release\": \"10\",\n",
      "    \"Version\": \"10.0.19045\",\n",
      "    \"machine\": \"AMD64\",\n",
      "    \"processor\": \"Intel64 Family 6 Model 165 Stepping 5, GenuineIntel\",\n",
      "    \"byteorder\": \"little\",\n",
      "    \"LC_ALL\": null,\n",
      "    \"LANG\": null,\n",
      "    \"LOCALE\": {\n",
      "      \"language-code\": \"de_DE\",\n",
      "      \"encoding\": \"cp1252\"\n",
      "    }\n",
      "  },\n",
      "  \"dependencies\": {\n",
      "    \"pandas\": \"2.2.3\",\n",
      "    \"numpy\": \"2.1.3\",\n",
      "    \"pytz\": \"2024.2\",\n",
      "    \"dateutil\": \"2.9.0.post0\",\n",
      "    \"pip\": \"23.2.1\",\n",
      "    \"Cython\": null,\n",
      "    \"sphinx\": null,\n",
      "    \"IPython\": \"8.29.0\",\n",
      "    \"adbc-driver-postgresql\": null,\n",
      "    \"adbc-driver-sqlite\": null,\n",
      "    \"bs4\": \"4.12.3\",\n",
      "    \"blosc\": null,\n",
      "    \"bottleneck\": null,\n",
      "    \"dataframe-api-compat\": null,\n",
      "    \"fastparquet\": null,\n",
      "    \"fsspec\": null,\n",
      "    \"html5lib\": null,\n",
      "    \"hypothesis\": null,\n",
      "    \"gcsfs\": null,\n",
      "    \"jinja2\": \"3.1.4\",\n",
      "    \"lxml.etree\": null,\n",
      "    \"matplotlib\": null,\n",
      "    \"numba\": null,\n",
      "    \"numexpr\": null,\n",
      "    \"odfpy\": null,\n",
      "    \"openpyxl\": null,\n",
      "    \"pandas_gbq\": null,\n",
      "    \"psycopg2\": null,\n",
      "    \"pymysql\": null,\n",
      "    \"pyarrow\": null,\n",
      "    \"pyreadstat\": null,\n",
      "    \"pytest\": null,\n",
      "    \"python-calamine\": null,\n",
      "    \"pyxlsb\": null,\n",
      "    \"s3fs\": null,\n",
      "    \"scipy\": \"1.14.1\",\n",
      "    \"sqlalchemy\": null,\n",
      "    \"tables\": null,\n",
      "    \"tabulate\": null,\n",
      "    \"xarray\": null,\n",
      "    \"xlrd\": null,\n",
      "    \"xlsxwriter\": null,\n",
      "    \"zstandard\": null,\n",
      "    \"tzdata\": \"2024.2\",\n",
      "    \"qtpy\": null,\n",
      "    \"pyqt5\": null\n",
      "  }\n",
      "}None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # optional\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "print(pd.show_versions(as_json=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b0e8e-9ba3-46fa-a7ab-c29e4715b843",
   "metadata": {},
   "source": [
    "### 2. How to create a series from a list, numpy array and dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8823a5c-ed32-4ccc-8ab2-d24f42377728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "e    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEine Pandas Series ist eine eindimensionale Datenstruktur, ähnlich einer Liste, einem Array oder einem Dictionary.\\nSie kombiniert Daten und Indizes, wodurch sie sehr flexibel und leistungsstark ist.\\nSeries werden häufig in der Datenanalyse, Zeitreihenverarbeitung und als Teil eines Pandas DataFrames verwendet.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "\n",
    "# Solution\n",
    "ser1 = pd.Series(mylist)\n",
    "ser2 = pd.Series(myarr)\n",
    "ser3 = pd.Series(mydict)\n",
    "print(ser3.head())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Eine Pandas Series ist eine eindimensionale Datenstruktur, ähnlich einer Liste, einem Array oder einem Dictionary.\n",
    "Sie kombiniert Daten und Indizes, wodurch sie sehr flexibel und leistungsstark ist.\n",
    "Series werden häufig in der Datenanalyse, Zeitreihenverarbeitung und als Teil eines Pandas DataFrames verwendet.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e80aaa-a77c-486e-a7fc-df27007133cd",
   "metadata": {},
   "source": [
    "### 3. How to convert the index of a series into a column of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5411ef12-56a0-4bbc-b444-63bb483be65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  0\n",
      "0     a  0\n",
      "1     b  1\n",
      "2     c  2\n",
      "3     e  3\n",
      "4     d  4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "\n",
    "# Solution\n",
    "df = ser.to_frame().reset_index()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfad70-1776-4d52-ab1a-a7d0d6469951",
   "metadata": {},
   "source": [
    "### 4. How to combine many series to form a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbb54ff-7593-4d6f-b404-b8699db178fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1  col2\n",
      "0    a     0\n",
      "1    b     1\n",
      "2    c     2\n",
      "3    e     3\n",
      "4    d     4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "\n",
    "# Solution 1\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "\n",
    "# Solution 2\n",
    "df = pd.DataFrame({'col1': ser1, 'col2': ser2})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b06cd4-8857-4b3b-af07-6166907838cf",
   "metadata": {},
   "source": [
    "### 5. How to assign name to the series’ index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70235336-98d9-4760-b200-42472534d940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    e\n",
       "4    d\n",
       "Name: alaphabet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser.name = \"alaphabet\"\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19560c86-feaf-432f-a41a-a2150b914916",
   "metadata": {},
   "source": [
    "### 6. How to get the items of series A not present in series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe819a6-606c-40ad-8119-727358caf4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "# Solution\n",
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157ef79-4928-4adb-901b-373372894d7e",
   "metadata": {},
   "source": [
    "### 7. How to get the items not common to both series A and series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf763da7-7597-46a8-b26c-d41e63c52639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "# Solution\n",
    "ser_u = pd.Series(np.union1d(ser1, ser2))  # union\n",
    "ser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\n",
    "ser_u[~ser_u.isin(ser_i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518243a-c57a-4a47-8253-1f69165c0316",
   "metadata": {},
   "source": [
    "### 8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c352b9-bdc3-44c3-b837-706940b63ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25117263,  7.70986507, 10.92259345, 13.36360403, 18.0949083 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "state = np.random.RandomState(100)\n",
    "ser = pd.Series(state.normal(10, 5, 25))\n",
    "\n",
    "# Solution\n",
    "np.percentile(ser, q=[0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d154b-bba7-4ee4-9894-919da074d0c6",
   "metadata": {},
   "source": [
    "### 9. How to get frequency counts of unique items of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839ebd81-ff0b-4838-91a2-f34f9c2d41c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     b\n",
      "1     b\n",
      "2     e\n",
      "3     d\n",
      "4     a\n",
      "5     c\n",
      "6     f\n",
      "7     e\n",
      "8     a\n",
      "9     b\n",
      "10    d\n",
      "11    g\n",
      "12    h\n",
      "13    g\n",
      "14    c\n",
      "15    f\n",
      "16    g\n",
      "17    h\n",
      "18    g\n",
      "19    a\n",
      "20    a\n",
      "21    a\n",
      "22    a\n",
      "23    b\n",
      "24    c\n",
      "25    e\n",
      "26    g\n",
      "27    g\n",
      "28    g\n",
      "29    a\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a    7\n",
       "g    7\n",
       "b    4\n",
       "e    3\n",
       "c    3\n",
       "d    2\n",
       "f    2\n",
       "h    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "print(ser)\n",
    "# Solution\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc3f5e-40ca-43ef-b0e8-9b0701a50cba",
   "metadata": {},
   "source": [
    "###  10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ebd757-9752-4b45-8e35-c6031ddc6dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     4\n",
      "3     4\n",
      "4     4\n",
      "5     4\n",
      "6     1\n",
      "7     3\n",
      "8     3\n",
      "9     1\n",
      "10    3\n",
      "11    2\n",
      "dtype: int32\n",
      "Top 2 Freq: 1    4\n",
      "4    4\n",
      "3    3\n",
      "2    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qather\\AppData\\Local\\Temp\\ipykernel_68332\\4045366092.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Other' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         4\n",
       "3         4\n",
       "4         4\n",
       "5         4\n",
       "6         1\n",
       "7     Other\n",
       "8     Other\n",
       "9         1\n",
       "10    Other\n",
       "11    Other\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "state = np.random.RandomState(100)\n",
    "ser = pd.Series(state.randint(1, 5, [12]))\n",
    "print(ser)\n",
    "\n",
    "# Solution\n",
    "print(\"Top 2 Freq:\", ser.value_counts())\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "ser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03020ab1-10d7-49a7-a071-392dcd6b6319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    1\n",
      "2    1\n",
      "3    3\n",
      "4    3\n",
      "dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    3\n",
       "2    1\n",
       "0    3\n",
       "dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series(np.random.randint(1,4,[5]))\n",
    "print(x)\n",
    "x[::~1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c3875-a52b-4a1b-8d45-7e1e5bb1d620",
   "metadata": {},
   "source": [
    "### 11. How to bin a numeric series to 10 groups of equal size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcde7b24-7c95-4550-b5c8-9d5f8b644dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.232891\n",
      "1    0.274082\n",
      "2    0.475438\n",
      "3    0.126276\n",
      "4    0.466606\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      4th\n",
       "1      4th\n",
       "2      7th\n",
       "3      2nd\n",
       "4      6th\n",
       "5      1st\n",
       "6      1st\n",
       "7      3rd\n",
       "8      9th\n",
       "9      8th\n",
       "10     5th\n",
       "11     2nd\n",
       "12     9th\n",
       "13     7th\n",
       "14    10th\n",
       "15    10th\n",
       "16     6th\n",
       "17     5th\n",
       "18     3rd\n",
       "19     8th\n",
       "dtype: category\n",
       "Categories (10, object): ['1st' < '2nd' < '3rd' < '4th' ... '7th' < '8th' < '9th' < '10th']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.random(20))\n",
    "print(ser.head())\n",
    "\n",
    "# Solution\n",
    "pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "        labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf10b3-77d4-41dc-bed3-c96561f4065c",
   "metadata": {},
   "source": [
    "### 12. How to convert a numpy array to a dataframe of given shape? (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b514c9-620b-47a0-bd28-082806ea4bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     7\n",
      "1     6\n",
      "2     1\n",
      "3     9\n",
      "4     1\n",
      "5     3\n",
      "6     6\n",
      "7     3\n",
      "8     5\n",
      "9     3\n",
      "10    7\n",
      "11    5\n",
      "12    9\n",
      "13    9\n",
      "14    5\n",
      "15    1\n",
      "16    5\n",
      "17    3\n",
      "18    2\n",
      "19    6\n",
      "20    3\n",
      "21    2\n",
      "22    9\n",
      "23    3\n",
      "24    3\n",
      "25    7\n",
      "26    8\n",
      "27    1\n",
      "28    3\n",
      "29    1\n",
      "30    8\n",
      "31    9\n",
      "32    6\n",
      "33    3\n",
      "34    1\n",
      "dtype: int32\n",
      "   0  1  2  3  4\n",
      "0  7  6  1  9  1\n",
      "1  3  6  3  5  3\n",
      "2  7  5  9  9  5\n",
      "3  1  5  3  2  6\n",
      "4  3  2  9  3  3\n",
      "5  7  8  1  3  1\n",
      "6  8  9  6  3  1\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "print(ser)\n",
    "\n",
    "# Solution\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54148db-4a7c-4d28-83f6-bd3528d31080",
   "metadata": {},
   "source": [
    "### 13. How to find the positions of numbers that are multiples of 3 from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc014d2-283f-4b96-8f1a-40dc2072a0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    8\n",
      "2    8\n",
      "3    5\n",
      "4    5\n",
      "5    5\n",
      "6    9\n",
      "dtype: int32\n",
      "[[6]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "ser\n",
    "\n",
    "# Solution\n",
    "print(ser)\n",
    "x = np.argwhere(ser % 3==0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d0d27-bf88-4725-8c8e-34016e7e26a2",
   "metadata": {},
   "source": [
    "### 14. How to extract items at given positions from a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38c9d33d-d7a1-45a8-9cfc-4ea85e219244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "\n",
    "# Solution\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e22dc8-97e2-48cc-89dc-c2a8fedca837",
   "metadata": {},
   "source": [
    "### 15. How to stack two series vertically and horizontally ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b2e306-3765-4edf-8810-bf2c08d13d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "dtype: object\n",
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "# Output\n",
    "# Vertical\n",
    "df = pd.concat([ser1, ser2])\n",
    "print(df)\n",
    "# Horizontal\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea95a3-3069-4d46-aae5-aebc578a0441",
   "metadata": {},
   "source": [
    "### 16. How to get the positions of items of series A in another series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deb7b5eb-f409-4e00-8de3-98ad927d0a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "# Solution 1\n",
    "[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "\n",
    "# Solution 2\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf478d-d4fd-4e6e-9ebc-d8db90274374",
   "metadata": {},
   "source": [
    "### 17. How to compute the mean squared error on a truth and predicted series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d6ae4c8-445e-4e3e-85cb-71b503c77e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4079518550550671)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "\n",
    "# Solution\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7705e09b-cc7f-4b98-8609-fe003dba6c14",
   "metadata": {},
   "source": [
    "### 18. How to convert the first character of each element in a series to uppercase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d639f879-5232-417c-80ad-fdff15dc1fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "# Solution 1\n",
    "ser.map(lambda x: x.title())\n",
    "\n",
    "# Solution 2\n",
    "ser.map(lambda x: x[0].upper() + x[1:])\n",
    "\n",
    "# Solution 3\n",
    "pd.Series([i.title() for i in ser])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e9b270-498c-4b79-96d1-d9cd94dc46e4",
   "metadata": {},
   "source": [
    "### 19. How to calculate the number of characters in each word in a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab0e4ff-9929-4b72-97ce-904283629002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "# Solution\n",
    "ser.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41599430-ccb1-423f-a522-e4dd0cb69bf3",
   "metadata": {},
   "source": [
    "### 20. How to compute difference of differences between consequtive numbers of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a10465b-e4e7-4ff6-a480-797973f2381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
      "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "# Solution\n",
    "print(ser.diff().tolist())\n",
    "print(ser.diff().diff().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cde2a7-18a1-4b5f-a8fc-037c71d8f0aa",
   "metadata": {},
   "source": [
    "### 21. How to convert a series of date-strings to a timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae8e076f-356b-47c3-8073-0272e2d4a44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d6d04e-4db9-4d83-a3e5-cb806df11ef4",
   "metadata": {},
   "source": [
    "### 22. How to get the day of month, week number, day of year and day of week from a series of date strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e65181b-8226-4311-965a-d3e3d9120f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week number:  [53, 5, 9, 14, 19, 23]\n",
      "Day number of year:  [1, 33, 63, 94, 125, 157]\n",
      "Day of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Solution\n",
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# day of month\n",
    "print(\"Date: \", ser_ts.dt.day.tolist())\n",
    "\n",
    "# week number\n",
    "print(\"Week number: \", ser_ts.dt.isocalendar().week.tolist())\n",
    "\n",
    "# day of year\n",
    "print(\"Day number of year: \", ser_ts.dt.dayofyear.tolist())\n",
    "\n",
    "# day of week\n",
    "print(\"Day of week: \", ser_ts.dt.day_name().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5137a4-2081-4aef-83c1-5d226d518f85",
   "metadata": {},
   "source": [
    "### 23. How to convert year-month string to dates corresponding to the 4th day of the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2671c9e0-afb7-453d-97ff-a88de7a6cd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]\n",
    "\n",
    "# Solution 2\n",
    "ser.map(lambda x: parse('04 ' + x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eae84f-5e28-4d30-9658-3fea5581e00e",
   "metadata": {},
   "source": [
    "### 24. How to filter words that contain atleast 2 vowels from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a58d6df7-d7fe-44a7-ade3-6aab9308cf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "\n",
    "# Solution\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ec6d5-3df9-4e24-8a51-7f0b260585a6",
   "metadata": {},
   "source": [
    "### 25. How to filter valid emails from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1b62de4-0700-44b9-87c2-37f9036ad15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "\n",
    "# Solution 1 (as series of strings)\n",
    "import re\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails[mask]\n",
    "\n",
    "# Solution 2 (as series of list)\n",
    "emails.str.findall(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# Solution 3 (as list)\n",
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b2a75-4a7a-45ac-b964-2c3233bb3fe4",
   "metadata": {},
   "source": [
    "### 26. How to get the mean of a series grouped by another series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea5cfdbf-1d09-4b17-9e7c-011155a5abb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     3.500000\n",
       "banana    6.833333\n",
       "carrot    3.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "\n",
    "# Solution\n",
    "weights.groupby(fruit).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072cf0b-3e1f-4152-a5fc-ed390aacc159",
   "metadata": {},
   "source": [
    "### 27. How to compute the euclidean distance between two series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76f23991-9853-4f8e-a43d-cd07647e0822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18.16590212458495)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "# Solution \n",
    "sum((p - q)**2)**.5\n",
    "\n",
    "# Solution (using func)\n",
    "np.linalg.norm(p-q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690cc46-3c6d-46fb-b22f-856d72289bdf",
   "metadata": {},
   "source": [
    "### 28. How to find all the local maxima (or peaks) in a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6994000-faac-44db-8f3b-96a992753645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "# Solution\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace6b58-bb3a-42fb-b483-5e74d39a49f6",
   "metadata": {},
   "source": [
    "### 29. How to replace missing spaces in a string with the least frequent character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cdc621c-e15c-41b2-8ad2-d3f97c2d29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    3\n",
      "     3\n",
      "e    3\n",
      "a    2\n",
      "c    1\n",
      "g    1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "my_str = 'dbc deb abed gade'\n",
    "\n",
    "# Solution\n",
    "ser = pd.Series(list('dbc deb abed gade'))\n",
    "freq = ser.value_counts()\n",
    "print(freq)\n",
    "least_freq = freq.dropna().index[-1]\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfcb65-7f69-407f-8184-a327f55d163d",
   "metadata": {},
   "source": [
    "### 30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6236b8fb-2a1f-488b-8f13-5ee845fb1668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    5\n",
       "2000-01-08    7\n",
       "2000-01-15    7\n",
       "2000-01-22    6\n",
       "2000-01-29    1\n",
       "2000-02-05    8\n",
       "2000-02-12    9\n",
       "2000-02-19    7\n",
       "2000-02-26    7\n",
       "2000-03-04    7\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a2551-559e-4aeb-959b-697f8207fd3e",
   "metadata": {},
   "source": [
    "### 31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63c0468a-8ea3-41bd-85a2-0d2af6d10b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([1,10,3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "# Solution\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "\n",
    "# Alternatives\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110c954-c9ac-4e96-86a8-87e09b0f71e0",
   "metadata": {},
   "source": [
    "### 32. How to compute the autocorrelations of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab42fa94-8ffd-49a8-9698-0e08c2c6f935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.44), np.float64(0.56), np.float64(0.31), np.float64(0.16), np.float64(0.15), np.float64(0.43), np.float64(-0.1), np.float64(0.45), np.float64(-0.05), np.float64(-0.1)]\n",
      "Lag having highest correlation:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAnwendungsfälle:\\n\\n    Analyse von Zeitreihen-Daten (z. B. Finanzdaten, Wetterdaten).\\n    Identifikation von Mustern oder Wiederholungen in Daten.\\n    Modellierung in der ARIMA-Zeitreihenanalyse (Bestimmung der AR-Parameter).\\n\\nDefiniton:\\n\\n    Das Beispiel zeigt, wie man die Autokorrelationen einer numerischen Zeitreihe berechnet.\\n    Autokorrelation misst die Korrelation einer Zeitreihe mit einer zeitlich verschobenen Version von sich selbst (Lags).\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)\n",
    "\n",
    "\"\"\"\n",
    "Anwendungsfälle:\n",
    "\n",
    "    Analyse von Zeitreihen-Daten (z. B. Finanzdaten, Wetterdaten).\n",
    "    Identifikation von Mustern oder Wiederholungen in Daten.\n",
    "    Modellierung in der ARIMA-Zeitreihenanalyse (Bestimmung der AR-Parameter).\n",
    "\n",
    "Definiton:\n",
    "\n",
    "    Das Beispiel zeigt, wie man die Autokorrelationen einer numerischen Zeitreihe berechnet.\n",
    "    Autokorrelation misst die Korrelation einer Zeitreihe mit einer zeitlich verschobenen Version von sich selbst (Lags).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcecbb-781d-495a-bad6-9c81f1cb0f70",
   "metadata": {},
   "source": [
    "### 33. How to import only every nth row from a csv file to create a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50ca7e10-8207-4e79-a490-56fa159e7846",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BostonHousing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Solution 3: Use csv reader\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m          \n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBostonHousing.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      9\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[0;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BostonHousing.csv'"
     ]
    }
   ],
   "source": [
    "# Solution 2: Use chunks and list comprehension\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n",
    "\n",
    "# Solution 3: Use csv reader\n",
    "import csv          \n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i%50 == 0:\n",
    "            out.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e602cc4-5bd4-42e9-a36c-3ab49d4fe858",
   "metadata": {},
   "source": [
    "### 34. How to change column values when importing csv to a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0250b4-9886-451d-b4b5-353bfd7f3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Using converter parameter\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n",
    "                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})\n",
    "\n",
    "\n",
    "# Solution 2: Using csv reader\n",
    "import csv\n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i > 0:\n",
    "            row[13] = 'High' if float(row[13]) > 25 else 'Low'\n",
    "        out.append(row)\n",
    "\n",
    "df = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98d917-ac5e-4bba-b4d8-b0479301996b",
   "metadata": {},
   "source": [
    "### 35. How to create a dataframe with rows as strides from a given series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2cf3c-5f6c-4a36-979d-d2da163978c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = pd.Series(range(15))\n",
    "\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7a75d-4973-494e-bfe0-43a6922a5619",
   "metadata": {},
   "source": [
    "### 36. How to import only specified columns from a csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3c0f2-8111-44f5-b826-99a398e6fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4cfb5-5423-40eb-98ba-3da1ed3cb13b",
   "metadata": {},
   "source": [
    "### 37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680df75-b0cf-4d00-bb6b-385558483dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "#  number of rows and columns\n",
    "print(df.shape)\n",
    "\n",
    "# datatypes\n",
    "print(df.dtypes)\n",
    "\n",
    "# how many columns under each dtype\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# summary statistics\n",
    "df_stats = df.describe()\n",
    "\n",
    "# numpy array \n",
    "df_arr = df.values\n",
    "\n",
    "# list\n",
    "df_list = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3d9ca-02da-479d-a267-7f44920a8206",
   "metadata": {},
   "source": [
    "### 38. How to extract the row and column number of a particular cell with given criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128d572-933c-4b83-970e-3fae4905946d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "# Get Manufacturer with highest price\n",
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Get Row and Column number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers. \n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a8d5b-8416-4c3d-bb42-0386bbc486de",
   "metadata": {},
   "source": [
    "### 39. How to rename a specific columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19990b-2c44-44ae-bae1-51054df277b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "# Step 1:\n",
    "df=df.rename(columns = {'Type':'CarType'})\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\"\n",
    "\n",
    "# Step 2:\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8d8e4-cb45-4b60-ba47-7200d6daf39d",
   "metadata": {},
   "source": [
    "### 40. How to check if a dataframe has any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edfb19f-52d7-41ec-9a28-15461fcb7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "df.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa4685-0bd8-49a7-80d8-cc0edf4a0668",
   "metadata": {},
   "source": [
    "### 41. How to count the number of missing values in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4e407-95f8-4fc3-bada-e23712678300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum())\n",
    "\n",
    "n_missings_each_col.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40496f1-470f-401a-9006-b7e65ee2b404",
   "metadata": {},
   "source": [
    "### 42. How to replace missing values of multiple numeric columns with the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868e32b-cc48-40f3-94f1-d8b05177c9bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "print(df)\n",
    "# Solution\n",
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out)\n",
    "\n",
    "\"\"\"\n",
    "Nutzen:\n",
    "\n",
    "Das Ersetzen von fehlenden Werten mit dem Mittelwert ist eine gängige Methode in der Datenvorbereitung, \n",
    "um sicherzustellen, dass Algorithmen keine Probleme mit fehlenden Werten haben.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81afde6-3066-4a41-ab4e-9c25b15dd04b",
   "metadata": {},
   "source": [
    "### 43. How to use apply function on existing columns with global variables as additional arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5897d-fe15-4413-a1de-fa29dd94f929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0e7c0-b103-4fa2-b217-24b5ca595f0c",
   "metadata": {},
   "source": [
    "### 44. How to select a specific column from a dataframe as a dataframe instead of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd01844-11ed-4e92-9133-1c489a3225ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Solution\n",
    "type(df[['a']])\n",
    "type(df.loc[:, ['a']])\n",
    "type(df.iloc[:, [0]])\n",
    "\n",
    "\"\"\"\n",
    "Was ist .loc?\n",
    "\n",
    "    .loc ist ein Label-basiertes Indexierungswerkzeug in Pandas.\n",
    "    Es wird verwendet, um Zeilen und Spalten anhand ihrer Namen (oder einer Liste von Namen) auszuwählen.\n",
    "    Es ist flexibel und unterstützt auch bedingte Filterung.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1c1d9-a5f2-46ac-957e-f8b381c9a294",
   "metadata": {},
   "source": [
    "### 45. How to change the order of columns of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee9e91-cf83-46ea-a697-f807ca251881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Solution Q1\n",
    "x = df[list('cbade')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b088f4-bde7-4060-be0b-39fa457bc6a5",
   "metadata": {},
   "source": [
    "### 46. How to set the number of rows and columns displayed in the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f456a-3e12-4601-a818-ea4b18941fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# df\n",
    "\n",
    "# Show all available options\n",
    "# pd.describe_option()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1149f0-80c2-47f7-b182-edaa8ba7c076",
   "metadata": {},
   "source": [
    "### 47. How to format or suppress scientific notations in a pandas dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cdc359-9e06-48c8-9662-7b5ac5f58c09",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Input\n",
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "\n",
    "\n",
    "# Solution 1: Rounding\n",
    "df.round(4)\n",
    "\n",
    "# Solution 2: Use apply to change format\n",
    "df.apply(lambda x: '%.4f' % x, axis=1)\n",
    "# or\n",
    "df.applymap(lambda x: '%.4f' % x)\n",
    "\n",
    "# Solution 3: Use set_option\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Solution 4: Assign display.float_format\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(df)\n",
    "\n",
    "# Reset/undo float formatting\n",
    "pd.options.display.float_format = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742da0d5-f991-435a-84e3-41122f497195",
   "metadata": {},
   "source": [
    "### 48. How to format all the values in a dataframe as percentages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf89a75-aab8-4619-a9c8-0957c5e2a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "\n",
    "# Solution\n",
    "out = df.style.format({\n",
    "    'random': '{0:.2%}'.format,\n",
    "})\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907deac2-9619-4843-b189-e2854667f7ba",
   "metadata": {},
   "source": [
    "### 49. How to filter every nth row in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ca334-f0b6-41bf-ab01-a9c4aa3b39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc42e2-337b-4818-9442-5587f99e7de8",
   "metadata": {},
   "source": [
    "### 50. How to create a primary key index by combining relevant columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82636b-aed8-4069-85ff-eb4439afbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n",
    "\n",
    "# Solution\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\n",
    "df.index = df.Manufacturer + '_' + df.Model + '_' + df.Type\n",
    "print(df.index.is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbef7e-8b15-4101-9e16-7b551374fbe2",
   "metadata": {},
   "source": [
    "### 51. How to get the row number of the nth largest value in a column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ad6ff-332b-418b-820f-30a25e93443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n",
    "\n",
    "# Solution\n",
    "n = 5\n",
    "df['a'].argsort()[::-1][n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb0a8c-a951-4ee8-87b8-c1b22b9eed08",
   "metadata": {},
   "source": [
    "### 52. How to find the position of the nth largest value greater than a given value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794f030-3e9a-4907-919f-5d807800bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 100, 15))\n",
    "\n",
    "# Solution\n",
    "print('ser: ', ser.tolist(), 'mean: ', round(ser.mean()))\n",
    "np.argwhere(ser > ser.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc5761-f8ea-4efe-92ef-7dd24dfb6d0e",
   "metadata": {},
   "source": [
    "### 53. How to get the last n rows of a dataframe with row sum > 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65649860-6f06-482a-a83e-f2ef756e9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "\n",
    "# Solution\n",
    "# print row sums\n",
    "rowsums = df.apply(np.sum, axis=1)\n",
    "\n",
    "# last two rows with row sum greater than 100\n",
    "last_two_rows = df.iloc[np.where(rowsums > 100)[0][-2:], :]\n",
    "print(last_two_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef41fe-d8ab-4925-a328-b8c33f1f0d26",
   "metadata": {},
   "source": [
    "### 54. How to find and cap outliers from a series or dataframe column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90d3cb-b7bb-478d-9aee-ac30cdec9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "print(ser)\n",
    "# Solution\n",
    "def cap_outliers(ser, low_perc, high_perc):\n",
    "    low, high = ser.quantile([low_perc, high_perc])\n",
    "    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high)\n",
    "    ser[ser < low] = low\n",
    "    ser[ser > high] = high\n",
    "    return(ser)\n",
    "\n",
    "capped_ser = cap_outliers(ser, .05, .95)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498efc3-74d3-4166-85fb-0cdaa9818f99",
   "metadata": {},
   "source": [
    "### 55. How to reshape a dataframe to the largest possible square after removing the negative values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6803f-cd0e-497d-9bb8-20698510fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))\n",
    "print(df)\n",
    "\n",
    "# Solution\n",
    "# Step 1: remove negative values from arr\n",
    "arr = df[df > 0].values.flatten()\n",
    "arr_qualified = arr[~np.isnan(arr)]\n",
    "\n",
    "# Step 2: find side-length of largest possible square\n",
    "n = int(np.floor(arr_qualified.shape[0]**.5))\n",
    "\n",
    "# Step 3: Take top n^2 items without changing positions\n",
    "top_indexes = np.argsort(arr_qualified)[::-1]\n",
    "output = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252863e3-5916-434e-ace3-8be31c04d980",
   "metadata": {},
   "source": [
    "### 56. How to swap two rows of a dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca923208-81dd-415c-8833-3c7c1f935956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "\n",
    "# Solution\n",
    "def swap_rows(df, i1, i2):\n",
    "    a, b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy()\n",
    "    df.iloc[i1, :], df.iloc[i2, :] = b, a\n",
    "    return df\n",
    "\n",
    "print(swap_rows(df, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd268a74-869b-409b-ad3a-889bd9cb0e6f",
   "metadata": {},
   "source": [
    "### 57. How to reverse the rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c036cc-16e0-4edb-8ae4-1a0e02c99f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "\n",
    "# Solution 1\n",
    "df.iloc[::-1, :]\n",
    "\n",
    "# Solution 2\n",
    "print(df.loc[df.index[::-1], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4813e2b-4426-4f2b-80c6-28d874205629",
   "metadata": {},
   "source": [
    "### 58. How to create one-hot encodings of a categorical variable (dummy variables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ee436-2c2d-4bd4-9aff-0c86ef2b1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "\n",
    "# Solution\n",
    "df_onehot = pd.concat([pd.get_dummies(df['a']), df[list('bcde')]], axis=1)\n",
    "print(df_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d0ff1-614e-4d7c-a999-b8e4d4915655",
   "metadata": {},
   "source": [
    "### 59. Which column contains the highest number of row-wise maximum values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c30c5e-da4a-4c65-a5eb-f317ef5e76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))\n",
    "\n",
    "# Solution\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2cebc-3d13-4c14-a66f-fb32ae7e7fb4",
   "metadata": {},
   "source": [
    "### 60. How to create a new column that contains the row number of nearest column by euclidean distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9deb9-e158-4350-bf33-2ec0c6d188c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "\n",
    "# Solution\n",
    "import numpy as np\n",
    "\n",
    "# init outputs\n",
    "nearest_rows = []\n",
    "nearest_distance = []\n",
    "\n",
    "# iterate rows.\n",
    "for i, row in df.iterrows():\n",
    "    curr = row\n",
    "    rest = df.drop(i)\n",
    "    e_dists = {}  # init dict to store euclidean dists for current row.\n",
    "    # iterate rest of rows for current row\n",
    "    for j, contestant in rest.iterrows():\n",
    "        # compute euclidean dist and update e_dists\n",
    "        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n",
    "    # update nearest row to current row and the distance value\n",
    "    nearest_rows.append(max(e_dists, key=e_dists.get))\n",
    "    nearest_distance.append(max(e_dists.values()))\n",
    "\n",
    "df['nearest_row'] = nearest_rows\n",
    "df['dist'] = nearest_distance\n",
    "\n",
    "\"\"\"\n",
    "1. Kategorisierung und Gruppierung von Daten\n",
    "\n",
    "    Wofür?\n",
    "        Um ähnliche Datenpunkte zu gruppieren oder Cluster zu identifizieren.\n",
    "    Beispiel:\n",
    "        In einer Produkttabelle: Finde ähnliche Produkte basierend auf Preis, Bewertung und Gewicht. Produkte mit der geringsten Distanz könnten zur gleichen Kategorie gehören.\n",
    "\n",
    "2. Empfehlungssysteme\n",
    "\n",
    "    Wofür?\n",
    "        Um ähnliche Objekte oder Datensätze zu finden und Empfehlungen zu erstellen.\n",
    "    Beispiel:\n",
    "        In einem Online-Shop:\n",
    "            Finde Produkte, die einem ausgewählten Produkt am ähnlichsten sind (z. B. basierend auf Merkmalen wie Preis, Bewertung, Farbe, etc.).\n",
    "        Benutzerempfehlungen:\n",
    "            Finde den Benutzer mit dem ähnlichsten Verhalten oder den nächstgelegenen Interessen.\n",
    "\n",
    "3. Anomalieerkennung\n",
    "\n",
    "    Wofür?\n",
    "        Um ungewöhnliche oder abweichende Datenpunkte zu identifizieren.\n",
    "    Beispiel:\n",
    "        In einem Netzwerküberwachungssystem:\n",
    "            Ein Datenpunkt (z. B. ein Benutzer) mit einer großen Distanz zu allen anderen könnte auf eine Anomalie hinweisen (z. B. potenziell bösartiges Verhalten).\n",
    "\n",
    "4. Clustering\n",
    "\n",
    "    Wofür?\n",
    "        Um Datensätze in sinnvolle Gruppen zu unterteilen.\n",
    "    Beispiel:\n",
    "        K-Means-Clustering (oder andere Clustering-Algorithmen) verwendet ähnliche Konzepte zur Berechnung der Distanzen zwischen Punkten, um Cluster zu erstellen.\n",
    "\n",
    "5. Ähnlichkeitsanalyse\n",
    "\n",
    "    Wofür?\n",
    "        Um Ähnlichkeiten zwischen Objekten basierend auf ihren Eigenschaften zu quantifizieren.\n",
    "    Beispiel:\n",
    "        Im Gesundheitswesen:\n",
    "            Finde Patienten mit ähnlichen Gesundheitsmerkmalen, um sie basierend auf Symptomen oder Krankheitsbildern zu klassifizieren.\n",
    "        In der Bildverarbeitung:\n",
    "            Finde das Bild, das einem gegebenen Bild am ähnlichsten ist, basierend auf extrahierten Merkmalen.\n",
    "\n",
    "6. Maschinelles Lernen: Vorhersagemodelle\n",
    "\n",
    "    Wofür?\n",
    "        Um Ähnlichkeiten zwischen Trainings- und Testdaten zu berechnen.\n",
    "    Beispiel:\n",
    "        Bei k-Nearest-Neighbors (k-NN):\n",
    "            Der Algorithmus verwendet Distanzen, um die k ähnlichsten Nachbarn eines Punktes zu finden und basierend darauf Vorhersagen zu treffen.\n",
    "\n",
    "7. Datenbereinigung\n",
    "\n",
    "    Wofür?\n",
    "        Um doppelte oder ähnliche Datensätze zu identifizieren und zu entfernen.\n",
    "    Beispiel:\n",
    "        In einer großen Tabelle mit Kundendaten:\n",
    "            Finde Zeilen, die fast identisch sind (z. B. denselben Namen, aber kleine Unterschiede bei der Telefonnummer haben).\n",
    "\n",
    "8. Visualisierung von Daten\n",
    "\n",
    "    Wofür?\n",
    "        Um Datenpunkte basierend auf ihrer Nähe in einer niedrigdimensionalen Darstellung zu platzieren.\n",
    "    Beispiel:\n",
    "        In einem Streudiagramm oder einem T-SNE-Diagramm:\n",
    "            Die Punkte, die nahe beieinander liegen, haben eine geringere euklidische Distanz, was Clusterbildung in visuellen Darstellungen zeigt.\n",
    "\n",
    "9. Zeitreihenanalyse\n",
    "\n",
    "    Wofür?\n",
    "        Um Zeitreihen-Daten miteinander zu vergleichen.\n",
    "    Beispiel:\n",
    "        Im Finanzwesen:\n",
    "            Finde die Aktie oder das Wertpapier, das sich in der Vergangenheit ähnlich wie ein bestimmtes Wertpapier verhalten hat (basierend auf Preisbewegungen).\n",
    "\n",
    "10. Lokale Nachbarschaftsanalysen\n",
    "\n",
    "    Wofür?\n",
    "        Um Beziehungen oder Interaktionen zwischen benachbarten Objekten zu untersuchen.\n",
    "    Beispiel:\n",
    "        In der Geodatenanalyse:\n",
    "            Finde den nächsten Standort zu einem gegebenen Standort (z. B. nächstgelegene Tankstelle zu einem bestimmten Punkt).\n",
    "        In sozialen Netzwerken:\n",
    "            Finde Benutzer, die am ähnlichsten sind, basierend auf gemeinsamen Interessen oder Verbindungen.\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1274b6-4ae7-4391-b488-7ee0038f747f",
   "metadata": {},
   "source": [
    "### 61. How to know the maximum possible correlation value of each column against other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b05680cd-84fa-4a87-8acf-e644ca96e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Correlation possible for each column:  [0.83 0.41 0.57 0.83 0.7  0.69 0.72 0.72 0.53 0.7 ]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n",
    "df\n",
    "\n",
    "# Solution\n",
    "abs_corrmat = np.abs(df.corr())\n",
    "max_corr = abs_corrmat.apply(lambda x: sorted(x)[-2])\n",
    "print('Maximum Correlation possible for each column: ', np.round(max_corr.tolist(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b106d-330d-4022-a225-57d7558b6023",
   "metadata": {},
   "source": [
    "### 62. How to create a column containing the minimum by maximum of each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb179df3-54dd-4c81-aec4-62cf04f87865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.065934\n",
      "1    0.072917\n",
      "2    0.104651\n",
      "3    0.071429\n",
      "4    0.043011\n",
      "5    0.077778\n",
      "6    0.055556\n",
      "7    0.075269\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution 1\n",
    "min_by_max = df.apply(lambda x: np.min(x)/np.max(x), axis=1)\n",
    "\n",
    "# Solution 2\n",
    "min_by_max = np.min(df, axis=1)/np.max(df, axis=1)\n",
    "\n",
    "print(min_by_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af423da-8f80-46de-8f19-9062be1dd741",
   "metadata": {},
   "source": [
    "### 63. How to create a column that contains the penultimate value in each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76b6994d-4ad2-4af8-a988-43d1707a194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    66\n",
      "1    79\n",
      "2    95\n",
      "3    82\n",
      "4    85\n",
      "5    73\n",
      "6    85\n",
      "7    72\n",
      "dtype: int32\n",
      "    0   1   2   3   4   5   6   7   8   9  penultimate\n",
      "0  21  26  62  66  58  70   2  37  25  35           66\n",
      "1  79  70  27  65  38  37  89  73  32  76           79\n",
      "2   3  56  79  87  99  81  69  94  32  95           95\n",
      "3  57  82  57   2  23  92  38  47  72  28           82\n",
      "4  36  95  71  38  71  56  32  85  30  42           85\n",
      "5  73  59  87  44  44  57  40  33  57  35           73\n",
      "6   5  96  79  13  85   3   2  51  96  15           85\n",
      "7  18  90  63   3   4  23  45  72  49   7           72\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution\n",
    "out = df.apply(lambda x: x.sort_values().unique()[-2], axis=1)\n",
    "print(out)\n",
    "df['penultimate'] = out\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac0cb7-001c-4ab4-9cfc-e4df1b6dbca3",
   "metadata": {},
   "source": [
    "### 64. How to normalize all columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecb15a2d-9b53-4d23-aa81-eabdb494ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard\n",
      "     0   1   2   3   4   5   6   7   8   9\n",
      "0  27  88   7  21  27  97  19  57  17  49\n",
      "1  98  16  41  45  72  68   9  36  16  90\n",
      "2  57   3  48  19  31  38  44  49  16  39\n",
      "3  63  40  27  37   7  73  14  21  19   4\n",
      "4  18  22  66  59  70  19  70  82  95  11\n",
      "5  28  67  72  32  53  71  31  29  73  24\n",
      "6  39  43  44  60   4  47  44  29  59  65\n",
      "7   3  51  26  78  61  93  98  82  94  20\n",
      "Solution Q1\n",
      "       0     1     2     3     4     5     6     7     8     9\n",
      "0 -0.49  1.68 -1.60 -1.11 -0.50  1.26 -0.73  0.37 -0.89  0.39\n",
      "1  1.88 -0.91 -0.02  0.05  1.15  0.18 -1.06 -0.51 -0.91  1.79\n",
      "2  0.51 -1.37  0.31 -1.20 -0.35 -0.94  0.09  0.04 -0.91  0.04\n",
      "3  0.71 -0.04 -0.67 -0.33 -1.24  0.36 -0.89 -1.14 -0.83 -1.16\n",
      "4 -0.79 -0.69  1.15  0.73  1.08 -1.65  0.95  1.42  1.30 -0.92\n",
      "5 -0.45  0.93  1.43 -0.58  0.46  0.29 -0.33 -0.80  0.68 -0.47\n",
      "6 -0.09  0.06  0.12  0.78 -1.35 -0.60  0.09 -0.80  0.29  0.93\n",
      "7 -1.28  0.35 -0.72  1.65  0.75  1.11  1.87  1.42  1.27 -0.61\n",
      "Solution Q2\n",
      "       0     1     2     3     4     5     6     7     8     9\n",
      "0  0.75  0.00  1.00  0.97  0.66  0.00  0.89  0.41  0.99  0.48\n",
      "1  0.00  0.85  0.48  0.56  0.00  0.37  1.00  0.75  1.00  0.00\n",
      "2  0.43  1.00  0.37  1.00  0.60  0.76  0.61  0.54  1.00  0.59\n",
      "3  0.37  0.56  0.69  0.69  0.96  0.31  0.94  1.00  0.96  1.00\n",
      "4  0.84  0.78  0.09  0.32  0.03  1.00  0.31  0.00  0.00  0.92\n",
      "5  0.74  0.25  0.00  0.78  0.28  0.33  0.75  0.87  0.28  0.77\n",
      "6  0.62  0.53  0.43  0.31  1.00  0.64  0.61  0.87  0.46  0.29\n",
      "7  1.00  0.44  0.71  0.00  0.16  0.05  0.00  0.00  0.01  0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHier ist die Erklärung des Codes:\\nInput\\n\\ndf = pd.DataFrame(np.random.randint(1, 100, 80).reshape(8, -1))\\n\\n    Ein DataFrame df wird erstellt:\\n        Enthält zufällige Ganzzahlen zwischen 1 und 100.\\n        Besteht aus 8 Zeilen und 10 Spalten.\\n\\nSolution Q1: Z-Score Berechnung\\nCode:\\n\\nout1 = df.apply(lambda x: ((x - x.mean()) / x.std()).round(2))\\n\\n    apply():\\n        Wendet die Lambda-Funktion spaltenweise an (standardmäßig axis=0).\\n    Lambda-Funktion:\\n        Z=x−μσZ=σx−μ\\u200b\\n            xx: Werte in der Spalte.\\n            μμ: Mittelwert der Spalte, berechnet mit x.mean().\\n            σσ: Standardabweichung der Spalte, berechnet mit x.std().\\n            Der Z-Score misst, wie viele Standardabweichungen ein Wert vom Mittelwert entfernt ist.\\n        round(2):\\n            Rundet das Ergebnis auf 2 Dezimalstellen.\\n    Ergebnis:\\n        Jede Zahl im DataFrame wird durch ihren Z-Score ersetzt, der ihre relative Position im Vergleich zur Verteilung der jeweiligen Spalte angibt.\\n\\nBeispiel:\\n\\nAngenommen, eine Spalte enthält: [10, 20, 30, 40].\\n\\n    Mittelwert μ=25μ=25, Standardabweichung σ≈12.91σ≈12.91.\\n    Z-Scores:\\n        Z(10)=10−2512.91≈−1.16Z(10)=12.9110−25\\u200b≈−1.16\\n        Z(20)=20−2512.91≈−0.39Z(20)=12.9120−25\\u200b≈−0.39\\n        ...\\n\\nSolution Q2: Min-Max-Skalierung\\nCode:\\n\\nout2 = df.apply(lambda x: ((x.max() - x) / (x.max() - x.min())).round(2))\\n\\n    apply():\\n        Wendet die Lambda-Funktion spaltenweise an.\\n    Lambda-Funktion:\\n        Scaled Value=max−xmax−minScaled Value=max−minmax−x\\u200b\\n            xx: Werte in der Spalte.\\n            maxmax: Maximale Zahl in der Spalte, berechnet mit x.max().\\n            minmin: Minimale Zahl in der Spalte, berechnet mit x.min().\\n            Skalierung der Werte, sodass der größte Wert den Skalenwert 0 hat und der kleinste den Skalenwert 1.\\n        round(2):\\n            Rundet die Ergebnisse auf 2 Dezimalstellen.\\n    Ergebnis:\\n        Die Werte jeder Spalte werden auf einen Bereich von 0 bis 1 skaliert.\\n\\nBeispiel:\\n\\nAngenommen, eine Spalte enthält: [10, 20, 30, 40].\\n\\n    min=10min=10, max=40max=40.\\n    Skalierte Werte:\\n        40−1040−10=1.040−1040−10\\u200b=1.0\\n        40−4040−10=0.040−1040−40\\u200b=0.0\\n\\nUnterschied zwischen Q1 und Q2\\n\\n    Q1 (Z-Score):\\n        Zentriert die Daten um den Mittelwert und skaliert basierend auf der Standardabweichung.\\n        Ergebnis: Werte sind negativ, positiv oder null, abhängig von ihrer Abweichung vom Mittelwert.\\n\\n    Q2 (Min-Max-Skalierung):\\n        Skaliert die Daten auf einen Bereich zwischen 0 und 1.\\n        Ergebnis: Werte sind normalisiert und behalten ihre relative Größenordnung bei.\\n\\n        '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "print('standard\\n',df)\n",
    "\n",
    "# Solution Q1\n",
    "out1 = df.apply(lambda x: ((x - x.mean())/x.std()).round(2))\n",
    "print('Solution Q1\\n',out1)\n",
    "\n",
    "# Solution Q2\n",
    "out2 = df.apply(lambda x: ((x.max() - x)/(x.max() - x.min())).round(2))\n",
    "print('Solution Q2\\n', out2)  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Hier ist die Erklärung des Codes:\n",
    "Input\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 80).reshape(8, -1))\n",
    "\n",
    "    Ein DataFrame df wird erstellt:\n",
    "        Enthält zufällige Ganzzahlen zwischen 1 und 100.\n",
    "        Besteht aus 8 Zeilen und 10 Spalten.\n",
    "\n",
    "Solution Q1: Z-Score Berechnung\n",
    "Code:\n",
    "\n",
    "out1 = df.apply(lambda x: ((x - x.mean()) / x.std()).round(2))\n",
    "\n",
    "    apply():\n",
    "        Wendet die Lambda-Funktion spaltenweise an (standardmäßig axis=0).\n",
    "    Lambda-Funktion:\n",
    "        Z=x−μσZ=σx−μ​\n",
    "            xx: Werte in der Spalte.\n",
    "            μμ: Mittelwert der Spalte, berechnet mit x.mean().\n",
    "            σσ: Standardabweichung der Spalte, berechnet mit x.std().\n",
    "            Der Z-Score misst, wie viele Standardabweichungen ein Wert vom Mittelwert entfernt ist.\n",
    "        round(2):\n",
    "            Rundet das Ergebnis auf 2 Dezimalstellen.\n",
    "    Ergebnis:\n",
    "        Jede Zahl im DataFrame wird durch ihren Z-Score ersetzt, der ihre relative Position im Vergleich zur Verteilung der jeweiligen Spalte angibt.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "Angenommen, eine Spalte enthält: [10, 20, 30, 40].\n",
    "\n",
    "    Mittelwert μ=25μ=25, Standardabweichung σ≈12.91σ≈12.91.\n",
    "    Z-Scores:\n",
    "        Z(10)=10−2512.91≈−1.16Z(10)=12.9110−25​≈−1.16\n",
    "        Z(20)=20−2512.91≈−0.39Z(20)=12.9120−25​≈−0.39\n",
    "        ...\n",
    "\n",
    "Solution Q2: Min-Max-Skalierung\n",
    "Code:\n",
    "\n",
    "out2 = df.apply(lambda x: ((x.max() - x) / (x.max() - x.min())).round(2))\n",
    "\n",
    "    apply():\n",
    "        Wendet die Lambda-Funktion spaltenweise an.\n",
    "    Lambda-Funktion:\n",
    "        Scaled Value=max−xmax−minScaled Value=max−minmax−x​\n",
    "            xx: Werte in der Spalte.\n",
    "            maxmax: Maximale Zahl in der Spalte, berechnet mit x.max().\n",
    "            minmin: Minimale Zahl in der Spalte, berechnet mit x.min().\n",
    "            Skalierung der Werte, sodass der größte Wert den Skalenwert 0 hat und der kleinste den Skalenwert 1.\n",
    "        round(2):\n",
    "            Rundet die Ergebnisse auf 2 Dezimalstellen.\n",
    "    Ergebnis:\n",
    "        Die Werte jeder Spalte werden auf einen Bereich von 0 bis 1 skaliert.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "Angenommen, eine Spalte enthält: [10, 20, 30, 40].\n",
    "\n",
    "    min=10min=10, max=40max=40.\n",
    "    Skalierte Werte:\n",
    "        40−1040−10=1.040−1040−10​=1.0\n",
    "        40−4040−10=0.040−1040−40​=0.0\n",
    "\n",
    "Unterschied zwischen Q1 und Q2\n",
    "\n",
    "    Q1 (Z-Score):\n",
    "        Zentriert die Daten um den Mittelwert und skaliert basierend auf der Standardabweichung.\n",
    "        Ergebnis: Werte sind negativ, positiv oder null, abhängig von ihrer Abweichung vom Mittelwert.\n",
    "\n",
    "    Q2 (Min-Max-Skalierung):\n",
    "        Skaliert die Daten auf einen Bereich zwischen 0 und 1.\n",
    "        Ergebnis: Werte sind normalisiert und behalten ihre relative Größenordnung bei.\n",
    "\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e53782-5221-4088-90ad-d5714856015e",
   "metadata": {},
   "source": [
    "### 65. How to compute the correlation of each row with the suceeding row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f96ac72c-e452-4666-81dc-7031f410ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  81   5  38  60   1  23  44  33  71   7\n",
      "1  91  87  12  30  44  23  46  70  42  53\n",
      "2  34  27  46  12  97  95  77  18  21  59\n",
      "3  81  47  12  81   8  55  72   8  62  77\n",
      "4  78  93  56  93  91  31  87  89  48  49\n",
      "5  70  73  17  57  38  74  90   1  20  85\n",
      "6  50  86  44   1   2  38  52  95  12  77\n",
      "7  36  27  83  33  96  70  53  63  38  34\n",
      "(8, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(0.04),\n",
       " np.float64(-0.34),\n",
       " np.float64(-0.16),\n",
       " np.float64(-0.14),\n",
       " np.float64(-0.04),\n",
       " np.float64(0.11),\n",
       " np.float64(-0.26)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "print(df)\n",
    "print(df.shape)\n",
    "# Solution\n",
    "[df.iloc[i].corr(df.iloc[i+1]).round(2) for i in range(df.shape[0])[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27d9a9-d44b-42a0-8104-fafe302e0c7b",
   "metadata": {},
   "source": [
    "### 66. How to replace both the diagonals of dataframe with 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d473ac26-e470-4cd5-8e20-396d7cb01639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0   0  38  49  43   8  77  58  63  58   0\n",
      "1  73   0   8  98  82  93  95  76   0  95\n",
      "2  38  27   0  88  46  44  80   0  87  66\n",
      "3  80  93  69   0  53  59   0  53  70  25\n",
      "4  40   7  79  26   0   0  83  62  28  83\n",
      "5   4  90  63  64   0   0  92  83  71  78\n",
      "6  89  33   8   0  61  86   0  65  71  30\n",
      "7  26  73   0  11  19  28  33   0  77  97\n",
      "8  20   0  65  77   8  75  12  97   0  59\n",
      "9   0  53  92  42  32  90  19   8  78   0\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "print(df.shape)\n",
    "# Solution\n",
    "for i in range(df.shape[0]):\n",
    "    df.iat[i, i] = 0\n",
    "    df.iat[df.shape[0]-i-1, i] = 0\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54775f04-6fc9-40df-8949-0d121e597a59",
   "metadata": {},
   "source": [
    "### 67. How to get the particular group of a groupby dataframe by key?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4245e6cb-fb4b-4a21-85a4-e59446bd6fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     col1      col2  col3\n",
      "0   apple  0.098283     1\n",
      "1  banana  0.266327     0\n",
      "2  orange  0.052968     1\n",
      "3   apple  0.421364     0\n",
      "4  banana  0.340880     1\n",
      "5  orange  0.190449    10\n",
      "6   apple  0.858929     5\n",
      "7  banana  0.671611    10\n",
      "8  orange  0.798728    12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qather\\AppData\\Local\\Temp\\ipykernel_68332\\3378235893.py:10: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  df_grouped.get_group('apple')\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "print(df)\n",
    "df_grouped = df.groupby(['col1'])\n",
    "\n",
    "# Solution 1\n",
    "df_grouped.get_group('apple')\n",
    "\n",
    "# Solution 2\n",
    "for i, dff in df_grouped:\n",
    "    if i == 'apple':\n",
    "        print(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c7ac1-a487-4b2a-9518-aa85bd5ba7b2",
   "metadata": {},
   "source": [
    "### 68. How to get the n’th largest value of a column when grouped by another column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "40dc1b9a-35c0-45c5-ae6c-1175cbf73d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gruppe: apple\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.993385\n",
       "3    0.892929\n",
       "6    0.524833\n",
       "Name: taste, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gruppe: banana\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.670832\n",
       "4    0.642960\n",
       "7    0.530410\n",
       "Name: taste, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gruppe: orange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    0.406961\n",
       "5    0.577310\n",
       "8    0.031290\n",
       "Name: taste, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6429599360698913)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'taste': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "\n",
    "# Solution\n",
    "df_grpd = df['taste'].groupby(df.fruit)\n",
    "\n",
    "for key, group in df_grpd:\n",
    "    print(f\"Gruppe: {key}\")\n",
    "    display(group)  # Zeigt jede Gruppe als Tabelle an\n",
    "    \n",
    "df_grpd.get_group('banana').sort_values().iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ad3e7-e5e9-4df5-852c-f5b43d33db64",
   "metadata": {},
   "source": [
    "### 69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c51b9444-ec73-471a-a434-c710da23894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit    rating  price\n",
      "0   apple  0.616558      6\n",
      "1  banana  0.982004      3\n",
      "2  orange  0.314064      4\n",
      "3   apple  0.146738      4\n",
      "4  banana  0.500235     12\n",
      "5  orange  0.391681      2\n",
      "6   apple  0.925812     13\n",
      "7  banana  0.693900      3\n",
      "8  orange  0.765410      4 \n",
      "\n",
      "    fruit     price\n",
      "0   apple  7.666667\n",
      "1  banana  6.000000\n",
      "2  orange  3.333333\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "print(df,'\\n')\n",
    "# Solution\n",
    "out = df.groupby('fruit', as_index=False)['price'].mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac990cd8-16cb-4495-a22c-45b0d54f9cee",
   "metadata": {},
   "source": [
    "### 70. How to join two dataframes by 2 columns so they have only the common rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fdc42961-2b5d-4c14-8caf-b0230d7b8a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>weight</th>\n",
       "      <th>price_left</th>\n",
       "      <th>pazham</th>\n",
       "      <th>kilo</th>\n",
       "      <th>price_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>10</td>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>7</td>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>12</td>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>apple</td>\n",
       "      <td>high</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>8</td>\n",
       "      <td>orange</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit weight  price_left  pazham  kilo  price_right\n",
       "0   apple   high          10   apple  high            7\n",
       "1  orange    low           3  orange   low            3\n",
       "2   apple   high           7   apple  high            7\n",
       "3  orange    low          12  orange   low            3\n",
       "4   apple   high           3   apple  high            7\n",
       "5  orange    low           8  orange   low            3"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})\n",
    "\n",
    "# Solution\n",
    "pd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['pazham', 'kilo'], suffixes=['_left', '_right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810b941-a5cf-4e7c-9161-d2fd1d828ee5",
   "metadata": {},
   "source": [
    "### 71. How to remove rows from a dataframe that are present in another dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2dbda143-0d17-4a63-956d-049bc1b79b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit  weight  price\n",
      "0   apple    high      0\n",
      "1  orange  medium      1\n",
      "2  banana     low      2\n",
      "3   apple    high      3\n",
      "4  orange  medium      4\n",
      "5  banana     low      5\n",
      "6   apple    high      6\n",
      "7  orange  medium      7\n",
      "8  banana     low      8 \n",
      "\n",
      "     fruit  weight  price\n",
      "0   apple    high      0\n",
      "1  orange  medium      1\n",
      "2    pine    high      2\n",
      "3   apple  medium      3\n",
      "4  orange    high      4\n",
      "5    pine  medium      5\n",
      "    fruit  weight  price\n",
      "2  banana     low      2\n",
      "3   apple    high      3\n",
      "4  orange  medium      4\n",
      "5  banana     low      5\n",
      "6   apple    high      6\n",
      "7  orange  medium      7\n",
      "8  banana     low      8\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'orange', 'banana'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.arange(9)})\n",
    "\n",
    "df2 = pd.DataFrame({'fruit': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'weight': ['high', 'medium'] * 3,\n",
    "                    'price': np.arange(6)})\n",
    "\n",
    "\n",
    "print(df1,'\\n''\\n',df2)\n",
    "# Solution\n",
    "print(df1[~df1.isin(df2).all(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7012ac6-ed3e-4692-a0f8-a153cfb04c58",
   "metadata": {},
   "source": [
    "### 72. How to get the positions where values of two columns match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cd24f9cd-841b-4b2c-aa89-f8c7eba19b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fruit1  fruit2\n",
      "0  banana  orange\n",
      "1  banana  orange\n",
      "2  orange  orange\n",
      "3   apple   apple\n",
      "4   apple   apple\n",
      "5  banana  banana\n",
      "6  orange  banana\n",
      "7  orange   apple\n",
      "8  banana   apple\n",
      "9  banana  banana\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 4, 5, 9]),)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Solution\n",
    "np.where(df.fruit1 == df.fruit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bbc74-9876-4e35-a44c-4283d7ba58a2",
   "metadata": {},
   "source": [
    "### 73. How to create lags and leads of a column in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "67b70c88-e1c9-46e2-9b20-8b941e8b04d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d  a_lag1  b_lead1\n",
      "0  33  99  46  62     NaN     60.0\n",
      "1  14  60  46  39    33.0     85.0\n",
      "2  38  85  80  50    14.0     23.0\n",
      "3  69  23   5   1    38.0     31.0\n",
      "4  41  31  20  79    69.0      NaN\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "# Solution\n",
    "df['a_lag1'] = df['a'].shift(1)\n",
    "df['b_lead1'] = df['b'].shift(-1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa6856-a992-44f7-916c-86e1a68296f9",
   "metadata": {},
   "source": [
    "### 74. How to get the frequency of unique values in the entire dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d62147f2-151f-4b24-a32c-c044801db057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c  d\n",
      "0  6  4  5  5\n",
      "1  7  8  9  7\n",
      "2  9  5  7  1\n",
      "3  5  2  9  9\n",
      "4  2  6  7  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5    5\n",
       "7    4\n",
       "9    4\n",
       "6    2\n",
       "2    2\n",
       "4    1\n",
       "8    1\n",
       "1    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "print(df)\n",
    "# Solution\n",
    "pd.Series(df.values.ravel()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5c6ac-ae84-4451-ac5b-129cd2fa321b",
   "metadata": {},
   "source": [
    "### 75. How to split a text column into two separate columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2cabf097-82a8-47f8-9292-d9243b9e5473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 STD            City    State\n",
      "1  33   Kolkata    West Bengal\n",
      "2  44    Chennai    Tamil Nadu\n",
      "3  40   Hyderabad    Telengana\n",
      "4  80   Bangalore    Karnataka\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "# Solution\n",
    "df_out = df.row.str.split(',|\\t', expand=True)\n",
    "\n",
    "# Make first row as header\n",
    "new_header = df_out.iloc[0]\n",
    "df_out = df_out[1:]\n",
    "df_out.columns = new_header\n",
    "print(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0745e08-dca5-42f3-b8f7-2bc2091c5ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
